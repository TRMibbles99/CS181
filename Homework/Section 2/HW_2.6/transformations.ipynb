{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denison CS-181/DA-210 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Transformations Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def add_modules():\n",
    "    \"\"\"\n",
    "    Starting at the current directory and proceeding up the file system\n",
    "    tree, search for a directory named `modules`.  If found, and if not\n",
    "    already there, add to the Python module search path.\n",
    "    \n",
    "    Params: None\n",
    "    \n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    directory = \".\"\n",
    "    levels = 0\n",
    "    while not os.path.isdir(os.path.join(directory, \"modules\")) and \\\n",
    "          levels < 5:\n",
    "        directory = os.path.join(directory, \"..\")\n",
    "        levels += 1\n",
    "    module_path = os.path.abspath(os.path.join(directory, \"modules\"))\n",
    "    if os.path.isdir(module_path):\n",
    "        if not module_path in sys.path:\n",
    "            sys.path.append(module_path)\n",
    "\n",
    "add_modules()\n",
    "import util\n",
    "\n",
    "datadir = util.resolve_dir(\"tabulardata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** Make the following into a `pandas` data frame, assigning it to variable `df1`.  Do not specify an index.\n",
    "\n",
    "    {'bar': ['one','two','one','two','one','two'],\n",
    "     'baz': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "     'foo': [1, 2, 3, 4, 5, 6]}\n",
    "     \n",
    "Suppose the values `A` and `B` and `C` from column `baz` should head columns (thus it takes more than one row to interpret a single observation, and `A`, `B`, and `C` really refer to variables), and the values themselves come from the `foo` column. \n",
    "\n",
    "Transform/reshape `df1` to obtain a tidy version of this data.  Your result **should only have one Index level for column labels**.  Assign to `transform1` and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Experimentation Cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655a07ec5e32f50c90747ae0e6d405f9",
     "grade": false,
     "grade_id": "cell-d5492318de6e628c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baz  A  B  C\n",
      "bar         \n",
      "one  1  3  5\n",
      "two  2  4  6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution Cell\n",
    "\n",
    "result = io.StringIO()\n",
    "with redirect_stdout(result):\n",
    "    df1 = pd.DataFrame.from_dict({'bar':['one','two','one','two','one','two'],\n",
    "                       'baz':['A','A','B','B','C','C'],\n",
    "                       'foo':[1,2,3,4,5,6]})\n",
    "    transform1 = df1.pivot(index='bar', columns='baz',values='foo')\n",
    "    print(transform1)\n",
    "print(result.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f25b15985082a4419bb7567e10e18bde",
     "grade": true,
     "grade_id": "cell-ddf3710987c31f0b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Cell\n",
    "\n",
    "assert isinstance(df1, pd.core.frame.DataFrame)\n",
    "assert isinstance(transform1, pd.core.frame.DataFrame)\n",
    "\n",
    "assert transform1.shape == (2, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** Make the following into a `pandas` data frame (with no index).  Assign it to `df2`.\n",
    "\n",
    "    {'A': {0: 2, 1: 4, 2: 6},\n",
    "    'B': {0: 'a', 1: 'b', 2: 'c'},\n",
    "    'C': {0: 1, 1: 3, 2: 5},\n",
    "    'D': {0: 1, 1: 2, 2: 4}}\n",
    "\n",
    "Suppose further that we have determined that columns labels `A` and `C` are really *values* of a *variable* called `X`.  Transform `df2` into a tidy form, making sure that `X` is appropriately labeled in the result.  You need not specify a value name.  Assign to `transform2`.  You need not print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  2  a  1  1\n",
       "1  4  b  3  2\n",
       "2  6  c  5  4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student Experimentation Cell\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aa82ff7647c893860e4bd3a7305a024",
     "grade": false,
     "grade_id": "cell-3f498aaf93b832dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>X</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  D  X  value\n",
       "0  a  1  A      2\n",
       "1  b  2  A      4\n",
       "2  c  4  A      6\n",
       "3  a  1  C      1\n",
       "4  b  2  C      3\n",
       "5  c  4  C      5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution Cell\n",
    "\n",
    "df2 = pd.DataFrame.from_dict({'A':{0:2,1:4,2:6},\n",
    "                             'B':{0:'a',1:'b',2:'c'},\n",
    "                             'C':{0:1,1:3,2:5},\n",
    "                             'D':{0:1,1:2,2:4}})\n",
    "transform2 = df2.melt(id_vars = ['B','D'], value_vars = ['A','C'], var_name = 'X')\n",
    "transform2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ee7c203a9ffd5846b2b07c79f222dba",
     "grade": true,
     "grade_id": "cell-9965e7d949aa3601",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "\n",
    "assert isinstance(df2, pd.core.frame.DataFrame)\n",
    "assert isinstance(transform2, pd.core.frame.DataFrame)\n",
    "\n",
    "assert transform2.shape == (6, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** Consider the file `restaurants_gender.csv`, that has aggregated rating data by gender and whose rows map from an id, restaurant, and gender to an average rating.  So, relative to this aggregation, the data is tidy as it stands.  Transform the `restaurants_gender` data into a matrix presentation with gender down one axis (as a row-label index) and restaurant across the other axis (as column label Index), a form that might make for good presentation. Store the result as `rest_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b4dc923b33370faf621fbe2b2a3f926",
     "grade": false,
     "grade_id": "cell-2e73568ee1e7d705",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    rating    \n",
       "restaurant  A  B      A   B\n",
       "gender                     \n",
       "F           1  3     82  57\n",
       "M           2  4     79  68"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution cell\n",
    "resturants_gender = pd.read_csv(os.path.join(datadir, 'restaurants_gender.csv'))\n",
    "rest_matrix = resturants_gender.pivot(index = 'gender', columns = 'restaurant')\n",
    "rest_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07c129392a8651cf868519929382d042",
     "grade": true,
     "grade_id": "cell-fc1ac55f8b8353cc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** Consider the file `ratings.csv`.  It has columns for first name, last name, `RatingA`, used for rating a particular restaurant (A), and `RatingB`, used for rating a different restaurant (B).  We want the name of a \"rater\" should be a single variable (a string with first name, a space, and then last name).  The particular restaurants (`A` and `B`) are *values* of the data set.  Transform the given dataset into a tidy data set, naming it `ratings_tidy`.  Do not give the new data set a row label index.  You need not print the result.\n",
    "\n",
    "Note that this question involves both transformation and mutations to normalize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6fda152f07c1ac4e2bf0b020055bd4c",
     "grade": false,
     "grade_id": "cell-47a506226ab66057",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>RatingA</th>\n",
       "      <th>RatingB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamid Hirst</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanya Hale</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wei Chang</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  RatingA  RatingB\n",
       "0  Hamid Hirst       73       52\n",
       "1   Tanya Hale       57       72\n",
       "2    Wei Chang       85       69"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution cell\n",
    "\n",
    "ratings_tidy = pd.read_csv(os.path.join(datadir, 'ratings.csv'))\n",
    "ratings_tidy['First'] = ratings_tidy['First'] +' '+ ratings_tidy['Last']\n",
    "del ratings_tidy['Last']\n",
    "ratings_tidy.rename(columns={'First':'Name'}, inplace = True)\n",
    "ratings_tidy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbb1108af49c0a80d3bbf2cdefd9fa92",
     "grade": true,
     "grade_id": "cell-624badf77eda14e8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "assert True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5** Read `us_rent_income.csv` into a dataframe, then understand the data. Note: this dataset contains estimated income and rent in each state, as well as the margin of error for each of these quantities. This data came from the US Census.\n",
    "\n",
    "Read the data into a data frame, `rent_income`, with no index.  Your goal is to make this into a tidy data set.  Hint: In a normalized version of this data set, the unique row index would be based on `GEOID` and `NAME` (which correspond one-for-one, and either could be the independent variable for the data).\n",
    "\n",
    "Name your tidy data set `rent_income_tidy`.  It is ok to have a two level column Index.  No need to print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Experimentation Cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6623ff1ea4a5820888264cb21b40a626",
     "grade": false,
     "grade_id": "cell-d95f0c30969f5978",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">estimate</th>\n",
       "      <th colspan=\"2\" halign=\"left\">moe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>income</th>\n",
       "      <th>rent</th>\n",
       "      <th>income</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>Alabama</th>\n",
       "      <td>24476.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>Alaska</th>\n",
       "      <td>32940.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>Arizona</th>\n",
       "      <td>27517.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>Arkansas</th>\n",
       "      <td>23789.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>California</th>\n",
       "      <td>29454.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>Colorado</th>\n",
       "      <td>32401.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>Connecticut</th>\n",
       "      <td>35326.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Delaware</th>\n",
       "      <td>31560.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>43198.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>Florida</th>\n",
       "      <td>25952.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>Georgia</th>\n",
       "      <td>27024.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>Hawaii</th>\n",
       "      <td>32453.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>Idaho</th>\n",
       "      <td>25298.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>Illinois</th>\n",
       "      <td>30684.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>Indiana</th>\n",
       "      <td>27247.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>Iowa</th>\n",
       "      <td>30002.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>Kansas</th>\n",
       "      <td>29126.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>Kentucky</th>\n",
       "      <td>24702.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>Louisiana</th>\n",
       "      <td>25086.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>Maine</th>\n",
       "      <td>26841.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>Maryland</th>\n",
       "      <td>37147.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>34498.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <th>Michigan</th>\n",
       "      <td>26987.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>Minnesota</th>\n",
       "      <td>32734.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>Mississippi</th>\n",
       "      <td>22766.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>Missouri</th>\n",
       "      <td>26999.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>Montana</th>\n",
       "      <td>26249.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <th>Nebraska</th>\n",
       "      <td>30020.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>Nevada</th>\n",
       "      <td>29019.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>33172.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <th>New Jersey</th>\n",
       "      <td>35075.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <th>New Mexico</th>\n",
       "      <td>24457.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <th>New York</th>\n",
       "      <td>31057.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <th>North Carolina</th>\n",
       "      <td>26482.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>North Dakota</th>\n",
       "      <td>32336.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>Ohio</th>\n",
       "      <td>27435.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>26207.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <th>Oregon</th>\n",
       "      <td>27389.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>28923.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>30210.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <th>South Carolina</th>\n",
       "      <td>25454.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <th>South Dakota</th>\n",
       "      <td>28821.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <th>Tennessee</th>\n",
       "      <td>25453.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th>Texas</th>\n",
       "      <td>28063.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <th>Utah</th>\n",
       "      <td>27928.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>Vermont</th>\n",
       "      <td>29351.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <th>Virginia</th>\n",
       "      <td>32545.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <th>Washington</th>\n",
       "      <td>32318.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <th>West Virginia</th>\n",
       "      <td>23707.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>29868.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <th>Wyoming</th>\n",
       "      <td>30854.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>NaN</td>\n",
       "      <td>464.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           estimate            moe      \n",
       "variable                     income    rent income  rent\n",
       "GEOID NAME                                              \n",
       "1     Alabama               24476.0   747.0  136.0   3.0\n",
       "2     Alaska                32940.0  1200.0  508.0  13.0\n",
       "4     Arizona               27517.0   972.0  148.0   4.0\n",
       "5     Arkansas              23789.0   709.0  165.0   5.0\n",
       "6     California            29454.0  1358.0  109.0   3.0\n",
       "8     Colorado              32401.0  1125.0  109.0   5.0\n",
       "9     Connecticut           35326.0  1123.0  195.0   5.0\n",
       "10    Delaware              31560.0  1076.0  247.0  10.0\n",
       "11    District of Columbia  43198.0  1424.0  681.0  17.0\n",
       "12    Florida               25952.0  1077.0   70.0   3.0\n",
       "13    Georgia               27024.0   927.0  106.0   3.0\n",
       "15    Hawaii                32453.0  1507.0  218.0  18.0\n",
       "16    Idaho                 25298.0   792.0  208.0   7.0\n",
       "17    Illinois              30684.0   952.0   83.0   3.0\n",
       "18    Indiana               27247.0   782.0  117.0   3.0\n",
       "19    Iowa                  30002.0   740.0  143.0   4.0\n",
       "20    Kansas                29126.0   801.0  208.0   5.0\n",
       "21    Kentucky              24702.0   713.0  159.0   4.0\n",
       "22    Louisiana             25086.0   825.0  155.0   4.0\n",
       "23    Maine                 26841.0   808.0  187.0   7.0\n",
       "24    Maryland              37147.0  1311.0  152.0   5.0\n",
       "25    Massachusetts         34498.0  1173.0  199.0   5.0\n",
       "26    Michigan              26987.0   824.0   82.0   3.0\n",
       "27    Minnesota             32734.0   906.0  189.0   4.0\n",
       "28    Mississippi           22766.0   740.0  194.0   5.0\n",
       "29    Missouri              26999.0   784.0  113.0   4.0\n",
       "30    Montana               26249.0   751.0  206.0   9.0\n",
       "31    Nebraska              30020.0   773.0  146.0   4.0\n",
       "32    Nevada                29019.0  1017.0  213.0   6.0\n",
       "33    New Hampshire         33172.0  1052.0  387.0   9.0\n",
       "34    New Jersey            35075.0  1249.0  148.0   4.0\n",
       "35    New Mexico            24457.0   809.0  214.0   6.0\n",
       "36    New York              31057.0  1194.0   69.0   3.0\n",
       "37    North Carolina        26482.0   844.0  111.0   3.0\n",
       "38    North Dakota          32336.0   775.0  245.0   9.0\n",
       "39    Ohio                  27435.0   764.0   94.0   2.0\n",
       "40    Oklahoma              26207.0   766.0  101.0   3.0\n",
       "41    Oregon                27389.0   988.0  146.0   4.0\n",
       "42    Pennsylvania          28923.0   885.0  119.0   3.0\n",
       "44    Rhode Island          30210.0   957.0  259.0   6.0\n",
       "45    South Carolina        25454.0   836.0  123.0   4.0\n",
       "46    South Dakota          28821.0   696.0  276.0   7.0\n",
       "47    Tennessee             25453.0   808.0  102.0   4.0\n",
       "48    Texas                 28063.0   952.0  110.0   2.0\n",
       "49    Utah                  27928.0   948.0  239.0   6.0\n",
       "50    Vermont               29351.0   945.0  361.0  11.0\n",
       "51    Virginia              32545.0  1166.0  202.0   5.0\n",
       "53    Washington            32318.0  1120.0  113.0   4.0\n",
       "54    West Virginia         23707.0   681.0  203.0   6.0\n",
       "55    Wisconsin             29868.0   813.0  135.0   3.0\n",
       "56    Wyoming               30854.0   828.0  342.0  11.0\n",
       "72    Puerto Rico               NaN   464.0    NaN   6.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent_income = pd.read_csv(os.path.join(datadir, 'us_rent_income.csv'))\n",
    "rent_income_tidy = rent_income.pivot(index = ['GEOID','NAME'], columns = 'variable', values = ['estimate','moe'])\n",
    "rent_income_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e48106c345e8bb4bc211a5b4f246e46",
     "grade": true,
     "grade_id": "cell-1cdab3a772de75a3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "\n",
    "assert(rent_income_tidy.shape == (52,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
