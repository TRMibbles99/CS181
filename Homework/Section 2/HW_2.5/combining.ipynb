{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denison CS-181/DA-210 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Tables Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def add_modules():\n",
    "    \"\"\"\n",
    "    Starting at the current directory and proceeding up the file system\n",
    "    tree, search for a directory named `modules`.  If found, and if not\n",
    "    already there, add to the Python module search path.\n",
    "    \n",
    "    Params: None\n",
    "    \n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    directory = \".\"\n",
    "    levels = 0\n",
    "    while not os.path.isdir(os.path.join(directory, \"modules\")) and \\\n",
    "          levels < 5:\n",
    "        directory = os.path.join(directory, \"..\")\n",
    "        levels += 1\n",
    "    module_path = os.path.abspath(os.path.join(directory, \"modules\"))\n",
    "    if os.path.isdir(module_path):\n",
    "        if not module_path in sys.path:\n",
    "            sys.path.append(module_path)\n",
    "\n",
    "add_modules()\n",
    "import util\n",
    "\n",
    "datadir = util.resolve_dir(\"tabulardata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** In the data directory, you will find two csv files, `educationTop.csv` and `educationBottom.csv`, both based on data hosted by `www.census.gov`. Both have the same columns, and each row is a U.S. metropolitan area, with data on population, education, and unemployment. The first `csv` file contains metropolitan areas starting with A-K, and the second starting with L-Z. Read both into `pandas` data frames, using the column `GEO.id2` as an index. Be careful, as these files have **two** lines that might be considered header lines.  The first one is more descriptive, and the second one is more concise and gives succint variable names.  So when we read from the csv, we want to **skip** the first line and then use the second line as the header line.  The `pandas` `read_csv` constructor can do this for you, but you have to discover and use the correct arguments.\n",
    "\n",
    "Concatenate these two data frames along the row dimension (with the top one on top), and call the result `educationDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Experimentation Cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4543416f790d229e1e2dadc98e0b8754",
     "grade": false,
     "grade_id": "cell-a07062440932fc45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id</th>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th>HD01_VD01</th>\n",
       "      <th>HD02_VD01</th>\n",
       "      <th>HD01_VD02</th>\n",
       "      <th>HD02_VD02</th>\n",
       "      <th>HD01_VD03</th>\n",
       "      <th>HD02_VD03</th>\n",
       "      <th>HD01_VD04</th>\n",
       "      <th>HD02_VD04</th>\n",
       "      <th>...</th>\n",
       "      <th>HD01_VD25</th>\n",
       "      <th>HD02_VD25</th>\n",
       "      <th>HD01_VD26</th>\n",
       "      <th>HD02_VD26</th>\n",
       "      <th>HD01_VD27</th>\n",
       "      <th>HD02_VD27</th>\n",
       "      <th>HD01_VD28</th>\n",
       "      <th>HD02_VD28</th>\n",
       "      <th>HD01_VD29</th>\n",
       "      <th>HD02_VD29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.id2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10180</th>\n",
       "      <td>310M100US10180</td>\n",
       "      <td>Abilene, TX Metro Area</td>\n",
       "      <td>82270</td>\n",
       "      <td>1582</td>\n",
       "      <td>13820</td>\n",
       "      <td>1873</td>\n",
       "      <td>6484</td>\n",
       "      <td>1272</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>579</td>\n",
       "      <td>347</td>\n",
       "      <td>12909</td>\n",
       "      <td>1564</td>\n",
       "      <td>12770</td>\n",
       "      <td>1557</td>\n",
       "      <td>139</td>\n",
       "      <td>137</td>\n",
       "      <td>3633</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>310M100US10420</td>\n",
       "      <td>Akron, OH Metro Area</td>\n",
       "      <td>369311</td>\n",
       "      <td>1080</td>\n",
       "      <td>26613</td>\n",
       "      <td>2972</td>\n",
       "      <td>14519</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>97693</td>\n",
       "      <td>4241</td>\n",
       "      <td>94492</td>\n",
       "      <td>4200</td>\n",
       "      <td>3201</td>\n",
       "      <td>888</td>\n",
       "      <td>13895</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>310M100US10500</td>\n",
       "      <td>Albany, GA Metro Area</td>\n",
       "      <td>78159</td>\n",
       "      <td>1072</td>\n",
       "      <td>13689</td>\n",
       "      <td>2238</td>\n",
       "      <td>7681</td>\n",
       "      <td>1645</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>12051</td>\n",
       "      <td>1611</td>\n",
       "      <td>11493</td>\n",
       "      <td>1472</td>\n",
       "      <td>558</td>\n",
       "      <td>507</td>\n",
       "      <td>2599</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10580</th>\n",
       "      <td>310M100US10580</td>\n",
       "      <td>Albany-Schenectady-Troy, NY Metro Area</td>\n",
       "      <td>466236</td>\n",
       "      <td>1818</td>\n",
       "      <td>29031</td>\n",
       "      <td>3211</td>\n",
       "      <td>16906</td>\n",
       "      <td>2415</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>572</td>\n",
       "      <td>510</td>\n",
       "      <td>146172</td>\n",
       "      <td>5083</td>\n",
       "      <td>142431</td>\n",
       "      <td>5036</td>\n",
       "      <td>3741</td>\n",
       "      <td>887</td>\n",
       "      <td>22891</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10740</th>\n",
       "      <td>310M100US10740</td>\n",
       "      <td>Albuquerque, NM Metro Area</td>\n",
       "      <td>476942</td>\n",
       "      <td>1656</td>\n",
       "      <td>51438</td>\n",
       "      <td>3778</td>\n",
       "      <td>30718</td>\n",
       "      <td>3015</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>1179</td>\n",
       "      <td>623</td>\n",
       "      <td>118976</td>\n",
       "      <td>5222</td>\n",
       "      <td>114318</td>\n",
       "      <td>5071</td>\n",
       "      <td>4658</td>\n",
       "      <td>986</td>\n",
       "      <td>21356</td>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GEO.id                       GEO.display-label  HD01_VD01  \\\n",
       "GEO.id2                                                                      \n",
       "10180    310M100US10180                  Abilene, TX Metro Area      82270   \n",
       "10420    310M100US10420                    Akron, OH Metro Area     369311   \n",
       "10500    310M100US10500                   Albany, GA Metro Area      78159   \n",
       "10580    310M100US10580  Albany-Schenectady-Troy, NY Metro Area     466236   \n",
       "10740    310M100US10740              Albuquerque, NM Metro Area     476942   \n",
       "\n",
       "         HD02_VD01  HD01_VD02  HD02_VD02  HD01_VD03  HD02_VD03  HD01_VD04  \\\n",
       "GEO.id2                                                                     \n",
       "10180         1582      13820       1873       6484       1272          0   \n",
       "10420         1080      26613       2972      14519       2048          0   \n",
       "10500         1072      13689       2238       7681       1645          0   \n",
       "10580         1818      29031       3211      16906       2415          0   \n",
       "10740         1656      51438       3778      30718       3015          0   \n",
       "\n",
       "         HD02_VD04  ...  HD01_VD25  HD02_VD25  HD01_VD26  HD02_VD26  \\\n",
       "GEO.id2             ...                                               \n",
       "10180          206  ...        579        347      12909       1564   \n",
       "10420          182  ...         43         70      97693       4241   \n",
       "10500          208  ...        247        249      12051       1611   \n",
       "10580          185  ...        572        510     146172       5083   \n",
       "10740          185  ...       1179        623     118976       5222   \n",
       "\n",
       "         HD01_VD27  HD02_VD27  HD01_VD28  HD02_VD28  HD01_VD29  HD02_VD29  \n",
       "GEO.id2                                                                    \n",
       "10180        12770       1557        139        137       3633        826  \n",
       "10420        94492       4200       3201        888      13895       1627  \n",
       "10500        11493       1472        558        507       2599        678  \n",
       "10580       142431       5036       3741        887      22891       1945  \n",
       "10740       114318       5071       4658        986      21356       2336  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution Cell\n",
    "educationTop = pd.read_csv(os.path.join(datadir,'educationTop.csv'), skiprows=1, index_col='GEO.id2')\n",
    "educationBot = pd.read_csv(os.path.join(datadir,'educationBottom.csv'), skiprows=1, index_col='GEO.id2')\n",
    "educationDF = pd.concat([educationTop, educationBot], axis=0)\n",
    "educationDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "496ce90981485567293a573ba4065575",
     "grade": true,
     "grade_id": "cell-b754829466f33be1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Cell\n",
    "\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** In the data directory, you will find two csv files, `educationLeft.csv` and `educationRight.csv`, both based on data hosted by `www.census.gov`. Both have the same rows, and each row is a U.S. metropolitan area, with data on population, education, and unemployment. The first has information on individuals without a college degree, and the second has information on individuals with a college degree. Read both into `pandas` data frames. The `GEO.display-label` field should serve as the row index.  Read these files into data frames and then concatenate these two data frames along the column dimension, and call the result `educationDF2`.\n",
    "\n",
    "The same cautions on the CSV having an informational row of headers followed by the header variable names applies to these two CSV files as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Experimentation Cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51ae42bc6c46a9d171a4f050c45db7c8",
     "grade": false,
     "grade_id": "cell-473a54cd9b85a26b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HD01_VD01</th>\n",
       "      <th>HD02_VD01</th>\n",
       "      <th>HD01_VD02</th>\n",
       "      <th>HD02_VD02</th>\n",
       "      <th>HD01_VD03</th>\n",
       "      <th>HD02_VD03</th>\n",
       "      <th>HD01_VD04</th>\n",
       "      <th>HD02_VD04</th>\n",
       "      <th>HD01_VD05</th>\n",
       "      <th>HD02_VD05</th>\n",
       "      <th>...</th>\n",
       "      <th>HD01_VD25</th>\n",
       "      <th>HD02_VD25</th>\n",
       "      <th>HD01_VD26</th>\n",
       "      <th>HD02_VD26</th>\n",
       "      <th>HD01_VD27</th>\n",
       "      <th>HD02_VD27</th>\n",
       "      <th>HD01_VD28</th>\n",
       "      <th>HD02_VD28</th>\n",
       "      <th>HD01_VD29</th>\n",
       "      <th>HD02_VD29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEO.display-label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene, TX Metro Area</th>\n",
       "      <td>82270</td>\n",
       "      <td>1582</td>\n",
       "      <td>13820</td>\n",
       "      <td>1873</td>\n",
       "      <td>6484</td>\n",
       "      <td>1272</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>6484</td>\n",
       "      <td>1272</td>\n",
       "      <td>...</td>\n",
       "      <td>579</td>\n",
       "      <td>347</td>\n",
       "      <td>12909</td>\n",
       "      <td>1564</td>\n",
       "      <td>12770</td>\n",
       "      <td>1557</td>\n",
       "      <td>139</td>\n",
       "      <td>137</td>\n",
       "      <td>3633</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron, OH Metro Area</th>\n",
       "      <td>369311</td>\n",
       "      <td>1080</td>\n",
       "      <td>26613</td>\n",
       "      <td>2972</td>\n",
       "      <td>14519</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>14519</td>\n",
       "      <td>2048</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>97693</td>\n",
       "      <td>4241</td>\n",
       "      <td>94492</td>\n",
       "      <td>4200</td>\n",
       "      <td>3201</td>\n",
       "      <td>888</td>\n",
       "      <td>13895</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany, GA Metro Area</th>\n",
       "      <td>78159</td>\n",
       "      <td>1072</td>\n",
       "      <td>13689</td>\n",
       "      <td>2238</td>\n",
       "      <td>7681</td>\n",
       "      <td>1645</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>7681</td>\n",
       "      <td>1645</td>\n",
       "      <td>...</td>\n",
       "      <td>247</td>\n",
       "      <td>249</td>\n",
       "      <td>12051</td>\n",
       "      <td>1611</td>\n",
       "      <td>11493</td>\n",
       "      <td>1472</td>\n",
       "      <td>558</td>\n",
       "      <td>507</td>\n",
       "      <td>2599</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany-Schenectady-Troy, NY Metro Area</th>\n",
       "      <td>466236</td>\n",
       "      <td>1818</td>\n",
       "      <td>29031</td>\n",
       "      <td>3211</td>\n",
       "      <td>16906</td>\n",
       "      <td>2415</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>16906</td>\n",
       "      <td>2415</td>\n",
       "      <td>...</td>\n",
       "      <td>572</td>\n",
       "      <td>510</td>\n",
       "      <td>146172</td>\n",
       "      <td>5083</td>\n",
       "      <td>142431</td>\n",
       "      <td>5036</td>\n",
       "      <td>3741</td>\n",
       "      <td>887</td>\n",
       "      <td>22891</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albuquerque, NM Metro Area</th>\n",
       "      <td>476942</td>\n",
       "      <td>1656</td>\n",
       "      <td>51438</td>\n",
       "      <td>3778</td>\n",
       "      <td>30718</td>\n",
       "      <td>3015</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>30718</td>\n",
       "      <td>3015</td>\n",
       "      <td>...</td>\n",
       "      <td>1179</td>\n",
       "      <td>623</td>\n",
       "      <td>118976</td>\n",
       "      <td>5222</td>\n",
       "      <td>114318</td>\n",
       "      <td>5071</td>\n",
       "      <td>4658</td>\n",
       "      <td>986</td>\n",
       "      <td>21356</td>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        HD01_VD01  HD02_VD01  HD01_VD02  \\\n",
       "GEO.display-label                                                         \n",
       "Abilene, TX Metro Area                      82270       1582      13820   \n",
       "Akron, OH Metro Area                       369311       1080      26613   \n",
       "Albany, GA Metro Area                       78159       1072      13689   \n",
       "Albany-Schenectady-Troy, NY Metro Area     466236       1818      29031   \n",
       "Albuquerque, NM Metro Area                 476942       1656      51438   \n",
       "\n",
       "                                        HD02_VD02  HD01_VD03  HD02_VD03  \\\n",
       "GEO.display-label                                                         \n",
       "Abilene, TX Metro Area                       1873       6484       1272   \n",
       "Akron, OH Metro Area                         2972      14519       2048   \n",
       "Albany, GA Metro Area                        2238       7681       1645   \n",
       "Albany-Schenectady-Troy, NY Metro Area       3211      16906       2415   \n",
       "Albuquerque, NM Metro Area                   3778      30718       3015   \n",
       "\n",
       "                                        HD01_VD04  HD02_VD04  HD01_VD05  \\\n",
       "GEO.display-label                                                         \n",
       "Abilene, TX Metro Area                          0        206       6484   \n",
       "Akron, OH Metro Area                            0        182      14519   \n",
       "Albany, GA Metro Area                           0        208       7681   \n",
       "Albany-Schenectady-Troy, NY Metro Area          0        185      16906   \n",
       "Albuquerque, NM Metro Area                      0        185      30718   \n",
       "\n",
       "                                        HD02_VD05  ...  HD01_VD25  HD02_VD25  \\\n",
       "GEO.display-label                                  ...                         \n",
       "Abilene, TX Metro Area                       1272  ...        579        347   \n",
       "Akron, OH Metro Area                         2048  ...         43         70   \n",
       "Albany, GA Metro Area                        1645  ...        247        249   \n",
       "Albany-Schenectady-Troy, NY Metro Area       2415  ...        572        510   \n",
       "Albuquerque, NM Metro Area                   3015  ...       1179        623   \n",
       "\n",
       "                                        HD01_VD26  HD02_VD26  HD01_VD27  \\\n",
       "GEO.display-label                                                         \n",
       "Abilene, TX Metro Area                      12909       1564      12770   \n",
       "Akron, OH Metro Area                        97693       4241      94492   \n",
       "Albany, GA Metro Area                       12051       1611      11493   \n",
       "Albany-Schenectady-Troy, NY Metro Area     146172       5083     142431   \n",
       "Albuquerque, NM Metro Area                 118976       5222     114318   \n",
       "\n",
       "                                        HD02_VD27  HD01_VD28  HD02_VD28  \\\n",
       "GEO.display-label                                                         \n",
       "Abilene, TX Metro Area                       1557        139        137   \n",
       "Akron, OH Metro Area                         4200       3201        888   \n",
       "Albany, GA Metro Area                        1472        558        507   \n",
       "Albany-Schenectady-Troy, NY Metro Area       5036       3741        887   \n",
       "Albuquerque, NM Metro Area                   5071       4658        986   \n",
       "\n",
       "                                        HD01_VD29  HD02_VD29  \n",
       "GEO.display-label                                             \n",
       "Abilene, TX Metro Area                       3633        826  \n",
       "Akron, OH Metro Area                        13895       1627  \n",
       "Albany, GA Metro Area                        2599        678  \n",
       "Albany-Schenectady-Troy, NY Metro Area      22891       1945  \n",
       "Albuquerque, NM Metro Area                  21356       2336  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution Cell\n",
    "educationLeft = pd.read_csv(os.path.join(datadir, \"educationLeft.csv\"), index_col= 'GEO.display-label', skiprows=1)\n",
    "educationRight = pd.read_csv(os.path.join(datadir, \"educationRight.csv\"), index_col= 'GEO.display-label',skiprows=1)\n",
    "educationDF2 = pd.concat([educationLeft, educationRight], axis=1)\n",
    "educationDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "899bb2ae297429b1e1e180459712ede9",
     "grade": true,
     "grade_id": "cell-544dd334b4f64648",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Cell\n",
    "\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** In the data directory, you will find two csv files, `educationLeftJ.csv` and `educationRightJ.csv`, both based on data hosted by `www.census.gov`. In both, rows represent U.S. metropolitan area, with data on population, education, and unemployment. However, they do not have exactly the same set of rows, and the columns are totally different except for the index column `Geography`. In these CSV files, there is not an \"extra\" header line.  The row label index should come from `Geography` unless you are instructed otherwise.\n",
    "\n",
    "0. Read both into `pandas` data frames, with names `educationLeftJ` and `educationRightJ`.\n",
    "1. Make a copy of `educationLeftJ` called `educationLeftOriginal`.\n",
    "2. Starting with `educationLeftJ`, do a left join to bring in the data from `educationRightJ`, storing your answer as `dfJ`.\n",
    "3. Starting with `educationLeftOriginal`, do an inner join to bring in the data from `educationRightJ`, storing your answer as `dfJ2`.\n",
    "4. Now read the original csv files in as `eduLeft` and `eduRight` with no meaningful index. Then, starting from `eduLeft`, do an inner merge along the column `Geography`, storing your answer as `dfJ3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Experimentation Cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa687f0b9f7858feea07d62c77840606",
     "grade": false,
     "grade_id": "cell-699089ddbb896d9d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 24)\n",
      "(152, 24)\n",
      "(152, 25)\n"
     ]
    }
   ],
   "source": [
    "# Solution Cell\n",
    "educationLeftJ = pd.read_csv(os.path.join(datadir, \"educationLeftJ.csv\"), index_col = \"Geography\")\n",
    "educationRightJ = pd.read_csv(os.path.join(datadir, \"educationRightJ.csv\"), index_col= \"Geography\")\n",
    "\n",
    "educationLeftOriginal = educationLeftJ.copy()\n",
    "\n",
    "dfJ = educationLeftJ.join(educationRightJ, how=\"left\")\n",
    "\n",
    "dfJ2 = educationLeftOriginal.join(educationRightJ, how=\"inner\")\n",
    "\n",
    "eduLeft = pd.read_csv(os.path.join(datadir, \"educationLeftJ.csv\"))\n",
    "eduRight = pd.read_csv(os.path.join(datadir, \"educationRightJ.csv\"))\n",
    "dfJ3 = pd.merge(eduLeft, eduRight, on='Geography', how='inner')\n",
    "print(dfJ.shape)\n",
    "print(dfJ2.shape)\n",
    "print(dfJ3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c677a70ca6db890a59d62c8cdd6d053",
     "grade": true,
     "grade_id": "cell-d404c99da0d1d157",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Cell\n",
    "\n",
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** Explain the difference in the number of rows and columns in `dfJ`, `dfJ2`, and `dfJ3`.  Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1b35495d2d22bb6f98fa9eeeb360311",
     "grade": true,
     "grade_id": "cell-0de313006f050137",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "We can see that educationLeftJ has more rows than educationRightJ because when merging left we have more rows than when doing an inner merge. So we know that educationLeftJ has 249 rows while they both share 152 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5** In the tabular data directory, there are csv files `students1.csv` and `majors.csv`.  Both are part of a multi-table data set we will use in our exploration of the relational data model.  The data set is based on a one year snapshot from Denison from 10 years ago, and then anonymized.  The `students1.csv` is a random selection of 50 students from the 2200 students in the full `students.csv`.\n",
    "\n",
    "Examine both of these tables using a spreadsheet type view and take a little time to understand the data (values, variables, and which of the vars are independent and dependent).\n",
    "\n",
    "The students table has information about students, including the up-to-four-character id indicating the major of the student, while the majors table relates the major id to the dependent variables of the full text name of the major and the up-to-four-character id of the *department* of the major.\n",
    "\n",
    "Suppose we want to compose a table, **sorted by last name, then first name**, of the students, and containing the columns: last name, first name, ethnicity, major id, department id, and major name, in that column order, and with an index of the studentid.  The table should be referred to by Python variable `studentmajors` when complete.  Note that some students will have missing data for their major (i.e. they have not selected a major yet), and that is ok, and they should not \"disappear\" from the composed table.\n",
    "\n",
    "Unlike the prior problems where the steps were pretty obvious from the set up, here you need to think about the \"right\" operation(s) and order of steps needed to combine the tables, order the columns appropriately, sort the rows appropriately, and to have the correct index.\n",
    "\n",
    "There will be multiple correct ways of solving this problem, and you are welcome to find the way that makes the most sense to you.  I strongly suggest that you work incrementally, and check your results after each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentid</th>\n",
       "      <th>studentfirst</th>\n",
       "      <th>studentlast</th>\n",
       "      <th>studentcity</th>\n",
       "      <th>studentstate</th>\n",
       "      <th>studentgender</th>\n",
       "      <th>studentethnicity</th>\n",
       "      <th>majorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61500</td>\n",
       "      <td>Gary</td>\n",
       "      <td>Ortega</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61501</td>\n",
       "      <td>Ayaan</td>\n",
       "      <td>Sarin</td>\n",
       "      <td>Newark</td>\n",
       "      <td>OH</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61502</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>Hoffman</td>\n",
       "      <td>Granville</td>\n",
       "      <td>OH</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61503</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Granville</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61504</td>\n",
       "      <td>Harini</td>\n",
       "      <td>Kapur</td>\n",
       "      <td>Pataskala</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>63769</td>\n",
       "      <td>Zachary</td>\n",
       "      <td>Hawkins</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>ENGW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>63770</td>\n",
       "      <td>James</td>\n",
       "      <td>Castillo</td>\n",
       "      <td>Granville</td>\n",
       "      <td>OH</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>63771</td>\n",
       "      <td>Aaradhya</td>\n",
       "      <td>Dasgupta</td>\n",
       "      <td>Heath</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>63772</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Hebron</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>63773</td>\n",
       "      <td>Sophie</td>\n",
       "      <td>Shaw</td>\n",
       "      <td>Granville</td>\n",
       "      <td>OH</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2274 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      studentid studentfirst studentlast  studentcity studentstate  \\\n",
       "0         61500         Gary      Ortega          NaN          NaN   \n",
       "1         61501        Ayaan       Sarin       Newark           OH   \n",
       "2         61502        Jacob     Hoffman    Granville           OH   \n",
       "3         61503         Sara        Hart    Granville           OH   \n",
       "4         61504       Harini       Kapur    Pataskala           OH   \n",
       "...         ...          ...         ...          ...          ...   \n",
       "2269      63769      Zachary     Hawkins  Los Angeles           CA   \n",
       "2270      63770        James    Castillo    Granville           OH   \n",
       "2271      63771     Aaradhya    Dasgupta        Heath           OH   \n",
       "2272      63772        Chloe    Campbell       Hebron           OH   \n",
       "2273      63773       Sophie        Shaw    Granville           OH   \n",
       "\n",
       "     studentgender studentethnicity majorid  \n",
       "0                M         Multiple     NaN  \n",
       "1                M            White     NaN  \n",
       "2                M            White     NaN  \n",
       "3                F            White     NaN  \n",
       "4                F            White     NaN  \n",
       "...            ...              ...     ...  \n",
       "2269             M            White    ENGW  \n",
       "2270             M            White     NaN  \n",
       "2271             F            White     NaN  \n",
       "2272             F            White     NaN  \n",
       "2273             F            Black     NaN  \n",
       "\n",
       "[2274 rows x 8 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student Experimentation Cell\n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94db06843268ec4ec7119238f1fd8780",
     "grade": false,
     "grade_id": "cell-2279c45ebb334084",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         studentethnicity majorid departmentid majorname\n",
      "studentlast studentfirst                                                \n",
      "Ortega      Gary                 Multiple     NaN          NaN       NaN\n",
      "Sarin       Ayaan                   White     NaN          NaN       NaN\n",
      "Hoffman     Jacob                   White     NaN          NaN       NaN\n",
      "Hart        Sara                    White     NaN          NaN       NaN\n",
      "Kapur       Harini                  White     NaN          NaN       NaN\n",
      "                         studentethnicity majorid departmentid  \\\n",
      "studentlast studentfirst                                         \n",
      "Hawkins     Zachary                 White    ENGW         ENGL   \n",
      "Castillo    James                   White     NaN          NaN   \n",
      "Dasgupta    Aaradhya                White     NaN          NaN   \n",
      "Campbell    Chloe                   White     NaN          NaN   \n",
      "Shaw        Sophie                  Black     NaN          NaN   \n",
      "\n",
      "                                  majorname  \n",
      "studentlast studentfirst                     \n",
      "Hawkins     Zachary       English (Writing)  \n",
      "Castillo    James                       NaN  \n",
      "Dasgupta    Aaradhya                    NaN  \n",
      "Campbell    Chloe                       NaN  \n",
      "Shaw        Sophie                      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Solution Cell\n",
    "students = pd.read_csv(os.path.join(datadir, 'students.csv'))\n",
    "majors = pd.read_csv(os.path.join(datadir, 'majors.csv'))\n",
    "\n",
    "studentmajors = pd.merge(students[['studentlast','studentfirst','studentethnicity','majorid']],majors[['majorid','departmentid','majorname']],how='left').set_index(['studentlast','studentfirst'])\n",
    "\n",
    "print(studentmajors.head())\n",
    "print(studentmajors.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc543bd060555f753a5a9ec2b0cad915",
     "grade": true,
     "grade_id": "cell-3b362211c0f27142",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Cell\n",
    "\n",
    "assert True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
